{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# MDL Assignment 3 Part 2:",
      "metadata": {
        "tags": [],
        "cell_id": "00000-0f197e39-c828-49cd-bd06-6aac7896998b",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00001-c079c31d-727c-4d25-8326-ae8684dd1ebd",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "d820ead1",
        "execution_millis": 0,
        "execution_start": 1620240340535,
        "deepnote_cell_type": "code"
      },
      "source": "rollno1 = 2019101030\nrollno2 = 2019101081\n\nx = 1 - ((rollno1%10**4)%30 + 1)/100\nsuccess_reward = rollno1%90 + 10",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00002-01f9114f-b577-4eed-af4b-4f2742621484",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "b20b1217",
        "execution_millis": 0,
        "execution_start": 1620240340582,
        "deepnote_cell_type": "code"
      },
      "source": "def mapper(position):\n    row , col = position\n    x = col\n    y = row\n    return(x, y)",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00002-09b3eff3-d37f-4349-92b4-8e77320fc090",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "3bced3a0",
        "execution_millis": 0,
        "execution_start": 1620240340583,
        "deepnote_cell_type": "code"
      },
      "source": "X = [0, 1, 2, 3]\nY = [0, 1]\ncall = [0, 1]\n\nX_MAX = 3\nY_MAX = 1\n\nALL_STATES = []\n\nfor x1 in X:\n    for y1 in Y:\n        for x2 in X:\n            for y2 in Y:\n                for state in call:\n                    ALL_STATES.append(((x1,y1),(x2,y2),state))\n\nACTION_STAY = 'Stay'\nACTION_UP = 'Up'\nACTION_DOWN = 'Down'\nACTION_LEFT = 'Left'\nACTION_RIGHT = 'Right'\n\nACTIONS = [ACTION_STAY, ACTION_UP, ACTION_DOWN, ACTION_LEFT, ACTION_RIGHT]\n\nO1 = \"o1\"\nO2 = \"o2\"\nO3 = \"o3\"\nO4 = \"o4\"\nO5 = \"o5\"\nO6 = \"o6\"\n\nOBSERVATIONS = [O1, O2, O3, O4, O5, O6]",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00002-f685cbfa-f151-4598-8c25-8a550947105f",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "8cd2a508",
        "execution_millis": 0,
        "execution_start": 1620240340593,
        "deepnote_cell_type": "code"
      },
      "source": "## Transition Matrix\n\ndef transition(state, action):\n    global success_reward\n    a_pos , t_pos, call = state\n\n    new_states = []\n    probabilities = [] \n    rewards = []\n\n    if(action == ACTION_LEFT):\n        # success\n        if(a_pos[0] == 0):\n            new_a_pos = (a_pos[0], a_pos[1])\n        else:\n            new_a_pos = (a_pos[0] - 1, a_pos[1])\n\n        new_states.append((new_a_pos, t_pos, call))\n        probabilities.append(x)\n        rewards.append(-1)\n\n        # failure\n        if(a_pos[0] == X_MAX):\n            new_a_pos = (a_pos[0], a_pos[1])\n        else:\n            new_a_pos = (a_pos[0] + 1, a_pos[1])\n\n        new_states.append((new_a_pos, t_pos, call))\n        probabilities.append(1-x)\n        rewards.append(-1)\n\n    elif(action == ACTION_RIGHT):\n        # success\n        if(a_pos[0] == X_MAX):\n            new_a_pos = (a_pos[0], a_pos[1])\n        else:\n            new_a_pos = (a_pos[0] + 1, a_pos[1])\n\n        new_states.append((new_a_pos, t_pos, call))\n        probabilities.append(x)\n        rewards.append(-1)\n\n        # failure\n        if(a_pos[0] == 0):\n            new_a_pos = (a_pos[0], a_pos[1])\n        else:\n            new_a_pos = (a_pos[0] - 1, a_pos[1])\n\n        new_states.append((new_a_pos, t_pos, call))\n        probabilities.append(1-x)\n        rewards.append(-1)\n\n\n    elif(action == ACTION_UP):\n        # success\n        if(a_pos[1] == Y_MAX):\n            new_a_pos = (a_pos[0], a_pos[1])\n        else:\n            new_a_pos = (a_pos[0], a_pos[1]+1)\n\n        new_states.append((new_a_pos, t_pos, call))\n        probabilities.append(x)\n        rewards.append(-1)\n\n        # failure\n        if(a_pos[1] == 0):\n            new_a_pos = (a_pos[0], a_pos[1])\n        else:\n            new_a_pos = (a_pos[0], a_pos[1]-1)\n\n        new_states.append((new_a_pos, t_pos, call))\n        probabilities.append(1-x)\n        rewards.append(-1)\n\n\n    elif(action == ACTION_DOWN):\n        # success\n        if(a_pos[1] == 0):\n            new_a_pos = (a_pos[0], a_pos[1])\n        else:\n            new_a_pos = (a_pos[0], a_pos[1]-1)\n\n        new_states.append((new_a_pos, t_pos, call))\n        probabilities.append(x)\n        rewards.append(-1)\n\n        # failure\n        if(a_pos[1] == Y_MAX):\n            new_a_pos = (a_pos[0], a_pos[1])\n        else:\n            new_a_pos = (a_pos[0], a_pos[1]+1)\n\n        new_states.append((new_a_pos, t_pos, call))\n        probabilities.append(1 - x)\n        rewards.append(-1)\n        \n    else:\n        #STAY\n        new_a_pos = (a_pos[0], a_pos[1])\n        new_states.append((new_a_pos, t_pos, call))\n        probabilities.append(1)\n        rewards.append(0)\n \n\n\n\n    l = len(new_states)\n    for i in range(l):\n        prob = probabilities[i]\n        a_pos, t_pos, call = new_states[i]\n        reward = rewards[i]\n\n        ## stays (dont append):\n        probabilities[i] = prob * 0.6\n\n\n        ## right\n        if(t_pos[0] == X_MAX):\n            new_t_pos = (t_pos[0], t_pos[1])\n        else:\n            new_t_pos = (t_pos[0] + 1, t_pos[1])\n\n        new_states.append((a_pos, new_t_pos, call))\n        probabilities.append(0.1 * prob)\n        rewards.append(reward)\n\n        ## left\n        if(t_pos[0] == 0):\n            new_t_pos = (t_pos[0], t_pos[1])\n        else:\n            new_t_pos = (t_pos[0] - 1, t_pos[1])\n\n        new_states.append((a_pos, new_t_pos, call))\n        probabilities.append(0.1 * prob)\n        rewards.append(reward)\n\n        ## up\n        if(t_pos[1] == Y_MAX):\n            new_t_pos = (t_pos[0], t_pos[1])\n        else:\n            new_t_pos = (t_pos[0], t_pos[1]+1)\n\n        new_states.append((a_pos, new_t_pos, call))\n        probabilities.append(0.1 * prob)\n        rewards.append(reward)\n\n        ## down \n        if(t_pos[1] == 0):\n            new_t_pos = (t_pos[0],t_pos[1])\n        else:\n            new_t_pos = (t_pos[0], t_pos[1]-1)\n\n        new_states.append((a_pos, new_t_pos, call))\n        probabilities.append(0.1 * prob)\n        rewards.append(reward)\n       \n\n    l = len(new_states)\n\n    for i in range(l):\n        a_pos, t_pos, call = new_states[i]\n        prob = probabilities[i]\n        \n        # Agent reached Target => Call turned off\n        if(a_pos == t_pos) and call == 1:\n            new_states[i] = (a_pos, t_pos, 0)\n            rewards[i] += success_reward\n        \n        # Call is on\n        elif call == 1:\n            # Call remains on\n            probabilities[i] = prob*0.9\n\n            # Call turns off\n            new_states.append((a_pos, t_pos, 0))\n            probabilities.append(prob*0.1)\n            rewards.append(rewards[i])\n\n        # Call is off\n        else:\n            # Call remains off\n            probabilities[i] = prob*0.5\n\n            # Call turn on\n            new_states.append((a_pos, t_pos, 1))\n            probabilities.append(prob*0.5)\n            rewards.append(rewards[i])\n\n\n    \n    final_states = []\n    final_probabilities = []\n    final_rewards = []\n\n    l = len(new_states)\n    for i in range(l):\n        if(new_states[i] in final_states):\n            final_probabilities[final_states.index(new_states[i])] += probabilities[i]\n        else:\n            final_states.append(new_states[i])\n            final_probabilities.append(probabilities[i])\n            final_rewards.append(rewards[i])\n\n    return final_states, final_probabilities, final_rewards",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00005-a2720109-42f1-41e1-ae22-ca5a0d71d9f0",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "e2540223",
        "execution_millis": 2,
        "execution_start": 1620240340594,
        "deepnote_cell_type": "code"
      },
      "source": "def observation(end_state):\n\n    pos1, pos2, status = end_state\n    x1,y1 = pos1\n    x2,y2 = pos2\n\n    if x1 == x2 and y1 == y2:\n        return O1\n    \n    elif x1+1 == x2 and y1 == y2:\n        return O2\n\n    elif x1 == x2 and y1-1 == y2:\n        return O3\n\n    elif x1-1 == x2 and y1 == y2:\n        return O4\n    \n    elif x1 == x2 and y1+1 == y2:\n        return O5\n\n    else:\n        return O6",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00006-60bf436e-2587-4392-ab53-b84570fcea03",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "6458a733",
        "execution_millis": 1,
        "execution_start": 1620240340619,
        "deepnote_cell_type": "code"
      },
      "source": "def parse(state):\n    a_pos, t_pos, call  = state\n    return \"S-\" + str(a_pos[0]) + str(a_pos[1])+ \"-\" + str(t_pos[0]) + str(t_pos[1]) + \"-\" + str(call) ",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00008-eff358e1-97dd-4621-8484-a0db43cfee24",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "a7ba3686",
        "execution_millis": 0,
        "execution_start": 1620240340620,
        "deepnote_cell_type": "code"
      },
      "source": "belief_state_q1 = []\ncheck_var = mapper((1,0))\n\nfor i in ALL_STATES:\n    pos1, pos2, state = i\n    if pos2 == check_var and (observation(i) == O6):\n        belief_state_q1.append(i)",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00008-913785e2-bff3-4453-9066-83812264c731",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "b1387b4b",
        "execution_millis": 0,
        "execution_start": 1620240340621,
        "deepnote_cell_type": "code"
      },
      "source": "belief_state_q2 = []\ncheck_var = mapper((1,1))\nfor i in ALL_STATES:\n    pos1, pos2, state = i\n    if pos1 == (1, 1) and (observation(i) == O1 or observation(i) == O2  or observation(i) == O3 or observation(i) == O4 or observation(i) == O5) and i[2] == 0:\n        belief_state_q2.append(i)",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00009-4dfc53b3-0be6-45a8-915b-eb31af84946f",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "cb669290",
        "execution_millis": 1,
        "execution_start": 1620240340621,
        "deepnote_cell_type": "code"
      },
      "source": "belief_state_q4 = []\nfor i in ALL_STATES:\n    pos1, pos2, state = i\n\n\n    ### all the coordinates are mapped manually\n\n    if(pos1 == (0,0)):\n        if pos2 == (1,0):\n            belief_state_q4.append(0.1/2)\n        elif pos2 == (2,0):\n            belief_state_q4.append(0.1/2)\n        elif pos2 == (1,1):\n            belief_state_q4.append(0.1/2)\n        elif pos2 == (2,1):\n            belief_state_q4.append(0.1/2)\n        else:\n            belief_state_q4.append(0)\n    \n    elif (pos1 == (3,1)):\n        if pos2 == (1,0):\n            belief_state_q4.append(0.15/2)\n        elif pos2 == (2,0):\n            belief_state_q4.append(0.15/2)\n        elif pos2 == (1,1):\n            belief_state_q4.append(0.15/2)\n        elif pos2 == (2,1):\n            belief_state_q4.append(0.15/2)\n        else:\n            belief_state_q4.append(0)\n\n    else:\n        belief_state_q4.append(0)\n",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00008-32082c0a-2f28-4148-9a45-5d6b5ba0ddca",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "655d600",
        "execution_millis": 14,
        "execution_start": 1620240340628,
        "deepnote_cell_type": "code"
      },
      "source": "f = open('file.pomdp','w')\nf.write(\"discount: 0.5\\n\")\nf.write(\"values: reward\\n\")\n\nf.write(\"states: \")\nfor i in ALL_STATES:\n    f.write(str(parse(i)) + \" \")\nf.write(\"\\n\")\n\nf.write(\"actions: \")\nfor i in ACTIONS:\n    f.write(str(i) + \" \")\nf.write(\"\\n\")\n\nf.write(\"observations: \")\nfor i in OBSERVATIONS:\n    f.write(str(i) + \" \")\nf.write(\"\\n\")",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "1"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00010-05d9769f-570b-47b3-9e71-329e92dec34e",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "b1b30d0d",
        "execution_millis": 8,
        "execution_start": 1620240340638,
        "deepnote_cell_type": "code"
      },
      "source": "f.write(\"start include: \")\nfor i in belief_state_q1:\n    f.write(str(parse(i)) + \" \")\nf.write(\"\\n\")",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "1"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00011-186f0629-a45d-4c0c-aba0-113bea902e35",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "f0102ab4",
        "execution_millis": 1,
        "execution_start": 1620240340715,
        "deepnote_cell_type": "code"
      },
      "source": "## \"T: <action> : <start-state> : <end-state> %f\"\nfor action in ACTIONS:\n    for state in ALL_STATES:\n        new_states, probabilities, rewards = transition(state, action)\n\n        l = len(new_states)\n        for i in range(l):\n            f.write(\"T : \" + action + \" : \" + str(parse(state)) + \" : \" +str(parse(new_states[i])) + \" \"  + \"%1.5f\"%(probabilities[i]) + \"\\n\") \n",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00012-9f4799fd-111e-43b2-9d0e-c5a4e228da25",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "4a66a87e",
        "execution_millis": 0,
        "execution_start": 1620240340760,
        "deepnote_cell_type": "code"
      },
      "source": "for i in ALL_STATES:\n    f.write(\"O : * : \"+str(parse(i))+\" : \"+observation(i)+\" 1.0 \\n\")",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00013-5a20f8ec-4105-43cd-be68-0b2c26118c60",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "7f265fc1",
        "execution_millis": 55,
        "execution_start": 1620240340760,
        "deepnote_cell_type": "code"
      },
      "source": "\nfor action in ACTIONS:\n    for state in ALL_STATES:\n        new_states, probabilities, rewards = transition(state, action)\n\n        l = len(new_states)\n        for i in range(l):\n            f.write(\"R : \" + action + \" : \" + str(parse(state)) + \" : \" +str(parse(new_states[i])) + \" : * \"  + \"%f\"%(rewards[i]) + \"\\n\") \n\nf.close()",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=10c6ce1f-e206-4ca6-a148-0fe16f2faac5' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 2,
    "deepnote": {
      "is_reactive": false
    },
    "deepnote_notebook_id": "e5c55ffc-e075-4d94-bb96-d51ec59be86a",
    "deepnote_execution_queue": []
  }
}